Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Fan2013,
abstract = {Determining how to select the tuning parameter appropriately is essential in penalized likelihood methods for high dimensional data analysis. We examine this problem in the setting of penalized likelihood methods for generalized linear models, where the dimensionality of covariates p is allowed to increase exponentially with the sample size n. We propose to select the tuning parameter by optimizing the generalized information criterion with an appropriate model complexity penalty. To ensure that we consistently identify the true model, a range for the model complexity penalty is identified in the generlized information criterion. We find that this model complexity penalty should diverge at the rate of some power of log (p) depending on the tail probability behaviour of the response variables. This reveals that using the Akaike information criterion or Bayes information criterion to select the tuning parameter may not be adequate for consistently identifying the true model. On the basis of our theoretical study, we propose a uniform choice of the model complexity penalty and show that the approach proposed consistently identifies the true model among candidate models with asymptotic probability 1. We justify the performance of the procedure proposed by numerical simulations and a gene expression data analysis. {\textcopyright} 2012 Royal Statistical Society.},
archivePrefix = {arXiv},
arxivId = {1605.03321},
author = {Fan, Yingying and Tang, Cheng Yong},
doi = {10.1111/rssb.12001},
eprint = {1605.03321},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Generalized information criterion,Generalized linear model,Penalized likelihood,Tuning parameter selection,Variable selection},
title = {{Tuning parameter selection in high dimensional penalized likelihood}},
year = {2013}
}

@article{Hui2015,
abstract = {The adaptive Lasso is a commonly applied penalty for variable selection in regression modeling. Like all penalties though, its performance depends critically on the choice of the tuning parameter. One method for choosing the tuning parameter is via information criteria, such as those based on AIC and BIC. However, these criteria were developed for use with unpenalized maximum likelihood estimators, and it is not clear that they take into account the effects of penalization. In this article, we propose the extended regularized information criterion (ERIC) for choosing the tuning parameter in adaptive Lasso regression. ERIC extends the BIC to account for the effect of applying the adaptive Lasso on the bias-variance tradeoff. This leads to a criterion whose penalty for model complexity is itself a function of the tuning parameter. We show the tuning parameter chosen by ERIC is selection consistent when the number of variables grows with sample size, and that this consistency holds in a wider range of contexts compared to using BIC to choose the tuning parameter. Simulation show that ERIC can significantly outperform BIC and other information criteria proposed (for choosing the tuning parameter) in selecting the true model. For ultra high-dimensional data (p {\textgreater} n), we consider a two-stage approach combining sure independence screening with adaptive Lasso regression using ERIC, which is selection consistent and performs strongly in simulation. Supplementary materials for this article are available online.},
author = {Hui, Francis K.C. and Warton, David I. and Foster, Scott D.},
doi = {10.1080/01621459.2014.951444},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {BIC,Consistency,High-dimensional data,Information criteria,Penalized likelihood,Regularization parameter,Variable selection},
title = {{Tuning Parameter Selection for the Adaptive Lasso Using ERIC}},
year = {2015}
}

@book{Hastie2009,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
booktitle = {Elements},
doi = {10.1007/978-0-387-84858-7},
isbn = {9780387848570},
issn = {01727397},
pmid = {15512507},
title = {{Elements of Statistical Learning 2nd ed.}},
year = {2009}
}

@article{Donohue2001,
abstract = {We offer evidence that legalized abortion has contributed significantly to recent crime reductions. Crime began to fall roughly eighteen years after abortion legalization. The five states that allowed abortion in 1970 experienced declines earlier than the rest of the nation, which legalized in 1973 with Roe v. Wade. States with high abortion rates in the 1970s and 1980s experienced greater crime reductions in the 1990s. In high abortion states, only arrests of those born after abortion legalization fall relative to low abortion states. Legalized abortion appears to account for as much as 50 percent of the recent drop in crime.},
author = {Donohue, John J. and Levitt, Steven D.},
doi = {10.1162/00335530151144050},
issn = {00335533},
journal = {Quarterly Journal of Economics},
title = {{The impact of legalized abortion on crime}},
year = {2001}
}

@article{Zhang2010,
	abstract = {We apply the nonconcave penalized likelihood approach to obtain variable selections as well as shrinkage estimators. This approach relies heavily on the choice of regularization parameter, which controls the model complexity. In this paper, we propose employing the generalized information criterion, encompassing the commonly used Akaike information criterion (AIC) and Bayesian information criterion (BIC), for selecting the regularization parameter. Our proposal makes a connection between the classical variable selection criteria and the regularization parameter selections for the nonconcave penalized likelihood approaches. We show that the BIC-type selector enables identification of the true model consistently, and the resulting estimator possesses the oracle property in the terminology of Fan and Li (2001). In contrast, however, the AIC-type selector tends to overfit with positive probability. We further show that the AIC-type selector is asymptotically loss efficient, while the BIC-type selector is not. Our simulation results confirm these theoretical findings, and an empirical example is presented. Some technical proofs are given in the online supplementary material. {\textcopyright} 2010 American Statistical Association.},
	author = {Zhang, Yiyun and Li, Runze and Tsai, Chih Ling},
	doi = {10.1198/jasa.2009.tm08013},
	issn = {01621459},
	journal = {J. Am. Stat. Assoc.},
	keywords = {Akaike information criterion,Bayesian information criterion,Least absolute shrinkage and selection operator,Nonconcave penalized likelihood,Smoothly clipped absolute deviation},
	title = {{Regularization parameter selections via generalized information criterion}},
	year = {2010}
}

@article{Belloni2012,
abstract = {We develop results for the use of Lasso and Post-Lasso methods to form first-stage predictions and estimate optimal instruments in linear instrumental variables (IV) models with many instruments, {\$}p{\$}. Our results apply even when {\$}p{\$} is much larger than the sample size, {\$}n{\$}. We show that the IV estimator based on using Lasso or Post-Lasso in the first stage is root-n consistent and asymptotically normal when the first-stage is approximately sparse; i.e. when the conditional expectation of the endogenous variables given the instruments can be well-approximated by a relatively small set of variables whose identities may be unknown. We also show the estimator is semi-parametrically efficient when the structural error is homoscedastic. Notably our results allow for imperfect model selection, and do not rely upon the unrealistic "beta-min" conditions that are widely used to establish validity of inference following model selection. In simulation experiments, the Lasso-based IV estimator with a data-driven penalty performs well compared to recently advocated many-instrument-robust procedures. In an empirical example dealing with the effect of judicial eminent domain decisions on economic outcomes, the Lasso-based IV estimator outperforms an intuitive benchmark. In developing the IV results, we establish a series of new results for Lasso and Post-Lasso estimators of nonparametric conditional expectation functions which are of independent theoretical and practical interest. We construct a modification of Lasso designed to deal with non-Gaussian, heteroscedastic disturbances which uses a data-weighted {\$}\backslashell{\_}1{\$}-penalty function. Using moderate deviation theory for self-normalized sums, we provide convergence rates for the resulting Lasso and Post-Lasso estimators that are as sharp as the corresponding rates in the homoscedastic Gaussian case under the condition that {\$}\backslashlog p = o(n{\^{}}{\{}1/3{\}}){\$}.},
archivePrefix = {arXiv},
arxivId = {1010.4345},
author = {Belloni, Alexandre and Chen, D and Chernozhukov, Victor and Hansen, Christian},
doi = {10.3982/ecta9626},
eprint = {1010.4345},
issn = {0012-9682},
journal = {Econometrica},
number = {6},
pages = {2369--2429},
title = {{Sparse Models and Methods for Optimal Instruments With an Application to Eminent Domain}},
volume = {80},
year = {2012}
}

@book{Wainwright2019,
	title={High-dimensional statistics: A non-asymptotic viewpoint},
	author={Wainwright, Martin J},
	volume={48},
	year={2019},
	publisher={Cambridge University Press}
}


@article{Chinco2019,
abstract = {How do arbitrageurs find variables that predict returns? If a predictor lasts 30 days or more, then a clever arbitrageur can use his intuition to get the job done. But, what's an arbitrageur supposed to do if a predictor lasts 30 minutes or less? An arbitrageur's intuition is useless if the predictor decays before he can finish his morning coffee. Motivated by this observation, we show how arbitrageurs can find these sorts of rare, short-lived, “sparse” predictors by replacing intuition with a statistical procedure known as the LASSO. Using the LASSO boosts out-of-sample predictability in 1-minute returns by 23{\%} relative to standard OLS-regression models. This out-of-sample predictive power comes from quickly identifying the right predictors at the right time, not from better estimating the effects of some new factor. What's more, the predictors chosen by the LASSO correspond to real-world events: the lagged returns of stocks with announcements are 18.3{\%} more likely to be used by the LASSO as predictors.},
author = {Chinco, Alex and Clark-Joseph, Adam D. and Ye, Mao},
doi = {10.1111/jofi.12733},
issn = {15406261},
journal = {Journal of Finance},
title = {{Sparse Signals in the Cross-Section of Returns}},
year = {2019}
}

@book{Khamsi2011,
abstract = {Metric spaces -- Metric contraction principles -- Hyperconvex spaces -- "Normal" structures in metric spaces -- Banach spaces : introduction -- Continuous mappings in Banach spaces -- Metric fixed point theory -- Banach space ultrapowers.},
author = {Khamsi, Mohamed A. and Kirk, William A.},
booktitle = {An Introduction to Metric Spaces and Fixed Point Theory},
doi = {10.1002/9781118033074},
title = {{An Introduction to Metric Spaces and Fixed Point Theory}},
year = {2001}
}

@article{Bickel2009,
abstract = {We exhibit an approximate equivalence between the Lasso estimator and Dantzig selector. For both methods we derive parallel oracle inequalities for the prediction risk in the general nonparametric regression model, as well as bounds on the {\$}\backslashell{\_}p{\$} estimation loss for {\$}1\backslashle p\backslashle 2{\$} in the linear model when the number of variables can be much larger than the sample size.},
author = {Bickel, Peter J. and Ritov, Ya'acov and Tsybakov, Alexandre B.},
doi = {10.1214/08-AOS620},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {Linear models,Model selection,Nonparametric statistics},
title = {{Simultaneous analysis of lasso and dantzig selector}},
year = {2009}
}

@misc{Tibshirani1996,
abstract = {Document: Details (1994) Robert Tibshirani CiteSeer.IST - Copyright Penn State and NEC},
archivePrefix = {arXiv},
arxivId = {1369–7412/11/73273},
author = {Tibshirani, Robert},
booktitle = {Journal of the Royal Statistical Society B},
doi = {10.2307/2346178},
eprint = {11/73273},
isbn = {0849320240},
issn = {00359246},
pmid = {16272381},
primaryClass = {1369–7412},
title = {{Regression Selection and Shrinkage via the Lasso}},
year = {1996}
}
@article{Buhlmann2011,
abstract = {Modern statistics deals with large and complex data sets, and consequently with models containing a large number of parameters. This book presents a detailed account of recently developed approaches, including the Lasso and ...},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {B{\"{u}}hlmann, P and Van de Geer, Sara},
doi = {10.1080/02664763.2012.694258},
eprint = {arXiv:1011.1669v3},
isbn = {9783642201929},
issn = {0266-4763},
journal = {Springer},
pmid = {15772297},
title = {{Statistics for High-Dimensional Data: Methods, Theory and Applications}},
year = {2011}
}
@article{Belloni2013,
abstract = {We propose robust methods for inference on the effect of a treatment variable on a scalar outcome in the presence of very many controls. Our setting is a partially linear model with possibly non-Gaussian and heteroscedastic disturbances where the number of controls may be much larger than the sample size. To make informative inference feasible, we require the model to be approximately sparse; that is, we require that the effect of confounding factors can be controlled for up to a small approximation error by conditioning on a relatively small number of controls whose identities are unknown. The latter condition makes it possible to estimate the treatment effect by selecting approximately the right set of controls. We develop a novel estimation and uniformly valid inference method for the treatment effect in this setting, called the “post-double-selection” method. Our results apply to Lasso-type methods used for covariate selection as well as to any other model selection method that is able to find a sparse model with good approximation properties.  The main attractive feature of our method is that it allows for imperfect selection of the controls and provides confidence intervals that are valid uniformly across a large class of models. In contrast, standard post-model selection estimators fail to provide uniform inference even in simple cases with a small, fixed number of controls. Thus our method resolves the problem of uniform inference after model selection for a large, interesting class of models. We illustrate the use of the developed methods with numerical simulations and an application to the effect of abortion on crime rates.},
archivePrefix = {arXiv},
arxivId = {1201.0224},
author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
doi = {10.1093/restud/rdt044},
eprint = {1201.0224},
isbn = {0895-3309},
issn = {1467937X},
journal = {Review of Economic Studies},
keywords = {Averagetreatment effects,High-dimensional-sparse regression,Inference under imperfect model selection,Lasso,Orthogonality of estimating equations with respect to nuisance parameters,Partially linear model,Treatment effects,Uniformly valid inference after model selection},
title = {{Inference on treatment effects after selection among high-dimensional controls}},
year = {2013}
}

@unpublished{Coutinho2017,
	author = {Coutinho, Daniel and Medeiros,Marcelo and Souza, Pedro},
	title = {{The Illusion of Independence: High Dimensional Data, Shrinkage Methods and Model Selection}},
	year = {2017},
	link = {http://www.econ.puc-rio.br/uploads/adm/trabalhos/files/Daniel_Martins_Coutinho.pdf}
}
